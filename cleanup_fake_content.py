#!/usr/bin/env python3
"""
Sahte/Placeholder iÃ§erikleri (Ã¶rn: 'London Spot') ve 
geÃ§erli fotoÄŸrafÄ± olmayan mekanlarÄ± JSON dosyalarÄ±ndan temizleyen script.
"""

import json
import os
from pathlib import Path

# KlasÃ¶r yolu
CITIES_DIR = Path("assets/cities")

# Silinecek jenerik terimler (kÃ¼Ã§Ã¼k harf)
FAKE_TERMS = [
    "london spot", "paris spot", "berlin spot", "city spot",
    "unknown place", "test place", "sample place",
    "lorem ipsum", "spot 1", "spot 2", "spot 3"
]

def is_fake(name: str) -> bool:
    """Ä°smin sahte/placeholder olup olmadÄ±ÄŸÄ±nÄ± kontrol et."""
    name_lower = name.lower()
    for term in FAKE_TERMS:
        if term in name_lower:
            return True
    
    # "Spot X" formatÄ± kontrolÃ¼ (regex yerine basit kontrol)
    if "spot" in name_lower and any(c.isdigit() for c in name_lower):
        return True
        
    return False

def has_valid_image(image_url: str) -> bool:
    """FotoÄŸraf URL'inin geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et."""
    if not image_url:
        return False
    if image_url == "":
        return False
    # Hala Unsplash ise (Google/Wiki bulunamadÄ±ysa) sil
    if "unsplash" in image_url.lower():
        return False
    return True

def process_city(json_path: Path) -> int:
    """Bir ÅŸehir dosyasÄ±nÄ± temizle."""
    
    city_name = json_path.stem.upper()
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    highlights = data.get("highlights", [])
    original_count = len(highlights)
    
    # Filtreleme
    valid_places = []
    removed_places = []
    
    for place in highlights:
        name = place.get("name", "Unknown")
        image_url = place.get("imageUrl", "")
        
        # 1. Fake isim kontrolÃ¼
        if is_fake(name):
            removed_places.append(f"{name} (Fake Name)")
            continue
            
        # 2. FotoÄŸraf kontrolÃ¼ (opsiyonel: eÄŸer fotoÄŸrafsÄ±z kalsÄ±n istemiyorsak)
        # KullanÄ±cÄ± "fake" lere kÄ±zdÄ±, fotoÄŸrafsÄ±zlara deÄŸil ama 
        # Unsplash olanlarÄ± da bulamadÄ±ysak silelim demiÅŸtik.
        if not has_valid_image(image_url):
            removed_places.append(f"{name} (No Image/Unsplash)")
            continue
            
        valid_places.append(place)
    
    # Sadece deÄŸiÅŸiklik varsa kaydet
    if len(valid_places) < original_count:
        data["highlights"] = valid_places
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        print(f"\nğŸ“ {city_name}: {original_count} -> {len(valid_places)} mekan")
        for removed in removed_places:
            print(f"  âŒ Silindi: {removed}")
        
        return len(removed_places)
    
    return 0

def main():
    print("=" * 60)
    print("ğŸ§¹ SAHTE Ä°Ã‡ERÄ°K TEMÄ°ZLÄ°ÄÄ°")
    print("=" * 60)
    
    json_files = list(CITIES_DIR.glob("*.json"))
    total_removed = 0
    
    for json_path in sorted(json_files):
        removed = process_city(json_path)
        total_removed += removed
    
    print("\n" + "=" * 60)
    print(f"âœ… TAMAMLANDI: Toplam {total_removed} sahte/bozuk mekan silindi.")
    print("=" * 60)

if __name__ == "__main__":
    main()
